Projeto de IngestÃ£o e AnÃ¡lise de Dados de ImunizaÃ§Ã£o COVID-19 no Cassandra

Este projeto tem como objetivo processar, limpar, ingerir e analisar dados de vacinaÃ§Ã£o contra COVID-19 utilizando:

Apache Cassandra (cluster com 3 nÃ³s em Docker)

dsbulk (DataStax Bulk Loader)

Python + pandas + matplotlib

VisualizaÃ§Ã£o de dados (grÃ¡ficos de barras e dispersÃ£o)

Dataset real do Kaggle, com 43 milhÃµes de registros

 RepositÃ³rio: https://github.com/Juniortech94/projeto_cassandra_imunizacao

 Dataset: https://www.kaggle.com/datasets/jsppimentel99/vacinao-covid-19-brasil-05-23

 Arquivo utilizado: Imu_COVID_RJ.csv

 Estrutura do Projeto
projeto_cassandra_imunizacao/
â”‚
â”œâ”€â”€ docker-compose.yml               # Cluster Cassandra com 3 nÃ³s
â”œâ”€â”€ prepare_csv.py                   # Limpeza + padronizaÃ§Ã£o do CSV com pandas
â”œâ”€â”€ amostragem.csv                   # Amostra usada para grÃ¡ficos
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ dsbulk.sh                    # Comandos de ingestÃ£o via dsbulk
â”‚
â”œâ”€â”€ graficos/
â”‚   â”œâ”€â”€ grafico_barra.py             # GeraÃ§Ã£o do grÃ¡fico de barras
â”‚   â””â”€â”€ grafico_dispersion.py        # GeraÃ§Ã£o do grÃ¡fico de dispersÃ£o
â”‚
â””â”€â”€ README.md                       

 Objetivo do Projeto

O objetivo foi construir um pipeline completo de ingestÃ£o de dados massivos envolvendo:

PreparaÃ§Ã£o dos dados com Python/pandas

ExecuÃ§Ã£o de um cluster Cassandra com 3 nÃ³s usando Docker

CriaÃ§Ã£o do keyspace e tabelas para consultas

IngestÃ£o de dados em larga escala usando o dsbulk

VisualizaÃ§Ã£o analÃ­tica para responder questÃµes de negÃ³cio


 1. PreparaÃ§Ã£o do Ambiente
 Subir o cluster Cassandra (3 nÃ³s)
docker compose up -d

 2. Estrutura da Tabela
CREATE KEYSPACE IF NOT EXISTS meu_projeto
WITH replication = {'class':'SimpleStrategy','replication_factor':3};

CREATE TABLE meu_projeto.imunizacao_covid (
    municipio int,
    data_aplicacao date,
    dose text,
    estabelecimento_municipio_codigo int,
    fabricante text,
    PRIMARY KEY (municipio, data_aplicacao)
);


Motivos do design:

municipio como partition key â†’ garante distribuiÃ§Ã£o e escalabilidade

data_aplicacao como clustering â†’ permite anÃ¡lises por tempo

 3. PrÃ©-processamento do CSV (pandas)

Arquivo: prepare_csv.py

FunÃ§Ãµes realizadas:

âœ” RemoÃ§Ã£o de colunas irrelevantes
âœ” ConversÃ£o de datas para o formato ISO
âœ” PadronizaÃ§Ã£o dos nomes
âœ” ExportaÃ§Ã£o em CSV limpo para ingestÃ£o

Executar:
python prepare_csv.py
Gera o arquivo:
imu_COVID_RJ_prepared.csv

 4. IngestÃ£o com DSBulk

Arquivo: scripts/dsbulk.sh

Exemplo de comando:

./dsbulk load \
  -h localhost \
  -k meu_projeto \
  -t imunizacao_covid \
  -url "imu_COVID_RJ_prepared.csv" \
  -header true \
  -delim "," \
  -m "municipio=municipio, estabelecimento_municipio_codigo=estabelecimento_municipio_codigo, data_aplicacao=vacina_dataAplicacao, fabricante=vacina_fabricante_nome, dose=vacina_descricao_dose"

ğŸ“Š 5. VisualizaÃ§Ãµes de Dados (grÃ¡ficos)

ğŸ“Œ **GrÃ¡fico de Barras â€” AplicaÃ§Ãµes por Fabricante**  
![GrÃ¡fico de Barras](imagens/grafico_barra.png)

Resultado: mostra qual fabricante teve maior volume de vacina aplicada.

ğŸ“Œ **GrÃ¡fico de DispersÃ£o â€” Data x MunicÃ­pio**  
![GrÃ¡fico de DispersÃ£o](imagens/grafico_dispersao.png)


Resultado: permite visualizar o comportamento temporal da vacinaÃ§Ã£o em diferentes municÃ­pios.

ConclusÃµes

O Cassandra mostrou-se eficiente para ingestÃ£o massiva de dados (43 milhÃµes de registros).

O dsbulk possibilitou ingestÃ£o paralela e otimizada, essencial para datasets grandes.

As visualizaÃ§Ãµes permitiram identificar padrÃµes relevantes para tomada de decisÃ£o.


